# Week 2: Feed-Forward Networks (FFN)

## Overview
This week covers the fundamentals of Feed-Forward Neural Networks, implementing them in multiple frameworks, and transitioning from toy examples to real applications. We'll explore the architecture, mathematics, and practical implementation aspects of FFNs.

## Learning Objectives
By the end of this week, students should be able to:
- Understand the basic architecture of feed-forward neural networks
- Implement FFNs using NumPy, PyTorch, and TensorFlow
- Compare and contrast different implementation approaches
- Debug common issues in neural network training
- Transition from simple to complex examples

## Topics Covered
1. **Neural Network Basics**
   - Neurons and activation functions
   - Forward propagation
   - Backpropagation
   - Loss functions and optimization

2. **Implementation in Different Frameworks**
   - Building an FFN from scratch using NumPy
   - PyTorch implementation
   - TensorFlow implementation
   - Comparing frameworks and their approaches

3. **From Toy Examples to Real Applications**
   - Simple classification problems
   - Regression tasks
   - Scaling to larger datasets
   - Best practices for model development

## Required Reading
- Deep Learning Book (Goodfellow et al.) - Chapter 6: Deep Feedforward Networks
- PyTorch Documentation - Neural Networks Tutorial
- TensorFlow Documentation - Keras Sequential API Guide

## Additional Resources
- Interactive visualizations of neural networks
- Code examples in each framework
- Debugging guides for common issues
